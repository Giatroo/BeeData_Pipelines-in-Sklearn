{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines do SkLearn\n",
    "\n",
    "Hoje vamos aprender uma ferramenta poderosíssima do `sklearn`: _pipelines_ (que em tradução literal é _oleoduto_, mas eu prefiro algo como _linha de montagem_). \n",
    "\n",
    "As pipelines nos permitem colocar em sequência todos o passos do nosso projeto de Machine Learning e também automatizar o pré-processamento, treinamento e afinação (_tuning_) de hiperparâmetros. Além disso, elas nos permitem fazer um `GridSearch` não só nos hyperparâmetros de um determinado modelo, mas também nos parâmetros que usamos no pré-processamento.\n",
    "\n",
    "- _Será que eu preencho os valores nulos com a média ou mediana?_\n",
    "- _Será que eu uso ou não essa determinada feature?_\n",
    "\n",
    "Essas entre outras perguntas são muito comuns quando estamos lidando com um projeto. As pipelines permitem que a gente ache exatamente qual é o melhor score que nossos modelos podem ter lidando com essas perguntas através de parâmetros que passamos para um `GridSearch`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importantando bibliotecas e dados\n",
    "\n",
    "Primeiro, como sempre, vamos importar as bibliotecas e dados que vamos utilizar.\n",
    "\n",
    "Esse tutorial foi inspirado no segundo capítulo do livro _Hands-On Machine Learning_, o notebook do capítulo pode ser encontrado no [GitHub](https://github.com/ageron/handson-ml2). Então vamos importar o data set utilizado por ele."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contextualizando, temos dados de casas no estado da California e seus preços, que é o que queremos predizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7027</th>\n",
       "      <td>-118.09</td>\n",
       "      <td>33.96</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1116.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>719.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>3.4250</td>\n",
       "      <td>163200.0</td>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17785</th>\n",
       "      <td>-121.84</td>\n",
       "      <td>37.37</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1579.0</td>\n",
       "      <td>339.0</td>\n",
       "      <td>1252.0</td>\n",
       "      <td>353.0</td>\n",
       "      <td>4.1615</td>\n",
       "      <td>214800.0</td>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20632</th>\n",
       "      <td>-121.45</td>\n",
       "      <td>39.26</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2319.0</td>\n",
       "      <td>416.0</td>\n",
       "      <td>1047.0</td>\n",
       "      <td>385.0</td>\n",
       "      <td>3.1250</td>\n",
       "      <td>115600.0</td>\n",
       "      <td>INLAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18185</th>\n",
       "      <td>-122.04</td>\n",
       "      <td>37.38</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2850.0</td>\n",
       "      <td>550.0</td>\n",
       "      <td>1518.0</td>\n",
       "      <td>514.0</td>\n",
       "      <td>4.2028</td>\n",
       "      <td>273600.0</td>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15773</th>\n",
       "      <td>-122.45</td>\n",
       "      <td>37.76</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2518.0</td>\n",
       "      <td>507.0</td>\n",
       "      <td>979.0</td>\n",
       "      <td>516.0</td>\n",
       "      <td>4.6912</td>\n",
       "      <td>500001.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10462</th>\n",
       "      <td>-117.64</td>\n",
       "      <td>33.48</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>397.0</td>\n",
       "      <td>1033.0</td>\n",
       "      <td>373.0</td>\n",
       "      <td>5.6754</td>\n",
       "      <td>275900.0</td>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15345</th>\n",
       "      <td>-117.38</td>\n",
       "      <td>33.21</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1502.0</td>\n",
       "      <td>367.0</td>\n",
       "      <td>1514.0</td>\n",
       "      <td>342.0</td>\n",
       "      <td>2.6442</td>\n",
       "      <td>103300.0</td>\n",
       "      <td>NEAR OCEAN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "7027     -118.09     33.96                36.0       1116.0           229.0   \n",
       "17785    -121.84     37.37                28.0       1579.0           339.0   \n",
       "20632    -121.45     39.26                15.0       2319.0           416.0   \n",
       "18185    -122.04     37.38                38.0       2850.0           550.0   \n",
       "15773    -122.45     37.76                50.0       2518.0           507.0   \n",
       "10462    -117.64     33.48                12.0       2007.0           397.0   \n",
       "15345    -117.38     33.21                31.0       1502.0           367.0   \n",
       "\n",
       "       population  households  median_income  median_house_value  \\\n",
       "7027        719.0       233.0         3.4250            163200.0   \n",
       "17785      1252.0       353.0         4.1615            214800.0   \n",
       "20632      1047.0       385.0         3.1250            115600.0   \n",
       "18185      1518.0       514.0         4.2028            273600.0   \n",
       "15773       979.0       516.0         4.6912            500001.0   \n",
       "10462      1033.0       373.0         5.6754            275900.0   \n",
       "15345      1514.0       342.0         2.6442            103300.0   \n",
       "\n",
       "      ocean_proximity  \n",
       "7027        <1H OCEAN  \n",
       "17785       <1H OCEAN  \n",
       "20632          INLAND  \n",
       "18185       <1H OCEAN  \n",
       "15773        NEAR BAY  \n",
       "10462       <1H OCEAN  \n",
       "15345      NEAR OCEAN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_path = 'housing.csv'\n",
    "df = pd.read_csv(input_path)\n",
    "df.sample(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que existem alguns valores nulos na coluna `total_bedrooms`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 10 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   longitude           20640 non-null  float64\n",
      " 1   latitude            20640 non-null  float64\n",
      " 2   housing_median_age  20640 non-null  float64\n",
      " 3   total_rooms         20640 non-null  float64\n",
      " 4   total_bedrooms      20433 non-null  float64\n",
      " 5   population          20640 non-null  float64\n",
      " 6   households          20640 non-null  float64\n",
      " 7   median_income       20640 non-null  float64\n",
      " 8   median_house_value  20640 non-null  float64\n",
      " 9   ocean_proximity     20640 non-null  object \n",
      "dtypes: float64(9), object(1)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pré-processamento sem pipelines\n",
    "\n",
    "Antes de ver como usar pipelines, vamos demonstrar como faríamos o pré-processamento dos dados sem elas.\n",
    "Os passos do pré-processamento serão:\n",
    "- Preencher os valores nulos\n",
    "- Normalizar e padronizar os valores numéricos\n",
    "- Codificar os valores categóricos utilizando One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 10 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   longitude           20640 non-null  float64\n",
      " 1   latitude            20640 non-null  float64\n",
      " 2   housing_median_age  20640 non-null  float64\n",
      " 3   total_rooms         20640 non-null  float64\n",
      " 4   total_bedrooms      20640 non-null  float64\n",
      " 5   population          20640 non-null  float64\n",
      " 6   households          20640 non-null  float64\n",
      " 7   median_income       20640 non-null  float64\n",
      " 8   median_house_value  20640 non-null  float64\n",
      " 9   ocean_proximity     20640 non-null  object \n",
      "dtypes: float64(9), object(1)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "def fill_na(df, strategy='median'):\n",
    "\n",
    "    num_values = list(df.columns[:-1])\n",
    "\n",
    "    imputer = SimpleImputer(strategy=strategy)\n",
    "    imputer.fit(df[num_values])\n",
    "    df[num_values] = imputer.transform(df[num_values])\n",
    "    return df\n",
    "\n",
    "\n",
    "df = fill_na(df)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19341</th>\n",
       "      <td>-1.647279</td>\n",
       "      <td>1.399006</td>\n",
       "      <td>1.856182</td>\n",
       "      <td>-0.514202</td>\n",
       "      <td>-0.450279</td>\n",
       "      <td>-0.581470</td>\n",
       "      <td>-0.380675</td>\n",
       "      <td>-0.884510</td>\n",
       "      <td>-0.406055</td>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1116</th>\n",
       "      <td>-1.018374</td>\n",
       "      <td>1.937421</td>\n",
       "      <td>-0.289187</td>\n",
       "      <td>-0.469280</td>\n",
       "      <td>-0.533735</td>\n",
       "      <td>-0.519656</td>\n",
       "      <td>-0.514070</td>\n",
       "      <td>-0.477778</td>\n",
       "      <td>-1.017011</td>\n",
       "      <td>INLAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12698</th>\n",
       "      <td>-0.928531</td>\n",
       "      <td>1.394324</td>\n",
       "      <td>0.346478</td>\n",
       "      <td>-0.158952</td>\n",
       "      <td>0.093378</td>\n",
       "      <td>-0.287413</td>\n",
       "      <td>0.009051</td>\n",
       "      <td>-0.895512</td>\n",
       "      <td>-0.963282</td>\n",
       "      <td>INLAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10342</th>\n",
       "      <td>0.938218</td>\n",
       "      <td>-0.857653</td>\n",
       "      <td>-1.878348</td>\n",
       "      <td>0.248554</td>\n",
       "      <td>0.224524</td>\n",
       "      <td>0.036667</td>\n",
       "      <td>0.213068</td>\n",
       "      <td>0.728206</td>\n",
       "      <td>0.262098</td>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16467</th>\n",
       "      <td>-0.848670</td>\n",
       "      <td>1.169595</td>\n",
       "      <td>0.823227</td>\n",
       "      <td>-0.009976</td>\n",
       "      <td>0.231677</td>\n",
       "      <td>0.385473</td>\n",
       "      <td>0.404007</td>\n",
       "      <td>-1.024790</td>\n",
       "      <td>-1.179933</td>\n",
       "      <td>INLAND</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "19341  -1.647279  1.399006            1.856182    -0.514202       -0.450279   \n",
       "1116   -1.018374  1.937421           -0.289187    -0.469280       -0.533735   \n",
       "12698  -0.928531  1.394324            0.346478    -0.158952        0.093378   \n",
       "10342   0.938218 -0.857653           -1.878348     0.248554        0.224524   \n",
       "16467  -0.848670  1.169595            0.823227    -0.009976        0.231677   \n",
       "\n",
       "       population  households  median_income  median_house_value  \\\n",
       "19341   -0.581470   -0.380675      -0.884510           -0.406055   \n",
       "1116    -0.519656   -0.514070      -0.477778           -1.017011   \n",
       "12698   -0.287413    0.009051      -0.895512           -0.963282   \n",
       "10342    0.036667    0.213068       0.728206            0.262098   \n",
       "16467    0.385473    0.404007      -1.024790           -1.179933   \n",
       "\n",
       "      ocean_proximity  \n",
       "19341       <1H OCEAN  \n",
       "1116           INLAND  \n",
       "12698          INLAND  \n",
       "10342       <1H OCEAN  \n",
       "16467          INLAND  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def scale(df):\n",
    "    num_values = list(df.columns[:-1])\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(df[num_values])\n",
    "    df[num_values] = scaler.transform(df[num_values])\n",
    "    return df\n",
    "\n",
    "\n",
    "df = scale(df)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity_&lt;1H OCEAN</th>\n",
       "      <th>ocean_proximity_INLAND</th>\n",
       "      <th>ocean_proximity_ISLAND</th>\n",
       "      <th>ocean_proximity_NEAR BAY</th>\n",
       "      <th>ocean_proximity_NEAR OCEAN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.327835</td>\n",
       "      <td>1.052548</td>\n",
       "      <td>0.982143</td>\n",
       "      <td>-0.804819</td>\n",
       "      <td>-0.972476</td>\n",
       "      <td>-0.974429</td>\n",
       "      <td>-0.977033</td>\n",
       "      <td>2.344766</td>\n",
       "      <td>2.129631</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.322844</td>\n",
       "      <td>1.043185</td>\n",
       "      <td>-0.607019</td>\n",
       "      <td>2.045890</td>\n",
       "      <td>1.357143</td>\n",
       "      <td>0.861439</td>\n",
       "      <td>1.669961</td>\n",
       "      <td>2.332238</td>\n",
       "      <td>1.314156</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.332827</td>\n",
       "      <td>1.038503</td>\n",
       "      <td>1.856182</td>\n",
       "      <td>-0.535746</td>\n",
       "      <td>-0.827024</td>\n",
       "      <td>-0.820777</td>\n",
       "      <td>-0.843637</td>\n",
       "      <td>1.782699</td>\n",
       "      <td>1.258693</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.337818</td>\n",
       "      <td>1.038503</td>\n",
       "      <td>1.856182</td>\n",
       "      <td>-0.624215</td>\n",
       "      <td>-0.719723</td>\n",
       "      <td>-0.766028</td>\n",
       "      <td>-0.733781</td>\n",
       "      <td>0.932968</td>\n",
       "      <td>1.165100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.337818</td>\n",
       "      <td>1.038503</td>\n",
       "      <td>1.856182</td>\n",
       "      <td>-0.462404</td>\n",
       "      <td>-0.612423</td>\n",
       "      <td>-0.759847</td>\n",
       "      <td>-0.629157</td>\n",
       "      <td>-0.012881</td>\n",
       "      <td>1.172900</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20635</th>\n",
       "      <td>-0.758826</td>\n",
       "      <td>1.801647</td>\n",
       "      <td>-0.289187</td>\n",
       "      <td>-0.444985</td>\n",
       "      <td>-0.388283</td>\n",
       "      <td>-0.512592</td>\n",
       "      <td>-0.443449</td>\n",
       "      <td>-1.216128</td>\n",
       "      <td>-1.115804</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20636</th>\n",
       "      <td>-0.818722</td>\n",
       "      <td>1.806329</td>\n",
       "      <td>-0.845393</td>\n",
       "      <td>-0.888704</td>\n",
       "      <td>-0.922403</td>\n",
       "      <td>-0.944405</td>\n",
       "      <td>-1.008420</td>\n",
       "      <td>-0.691593</td>\n",
       "      <td>-1.124470</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20637</th>\n",
       "      <td>-0.823713</td>\n",
       "      <td>1.778237</td>\n",
       "      <td>-0.924851</td>\n",
       "      <td>-0.174995</td>\n",
       "      <td>-0.123608</td>\n",
       "      <td>-0.369537</td>\n",
       "      <td>-0.174042</td>\n",
       "      <td>-1.142593</td>\n",
       "      <td>-0.992746</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20638</th>\n",
       "      <td>-0.873626</td>\n",
       "      <td>1.778237</td>\n",
       "      <td>-0.845393</td>\n",
       "      <td>-0.355600</td>\n",
       "      <td>-0.304827</td>\n",
       "      <td>-0.604429</td>\n",
       "      <td>-0.393753</td>\n",
       "      <td>-1.054583</td>\n",
       "      <td>-1.058608</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20639</th>\n",
       "      <td>-0.833696</td>\n",
       "      <td>1.750146</td>\n",
       "      <td>-1.004309</td>\n",
       "      <td>0.068408</td>\n",
       "      <td>0.188757</td>\n",
       "      <td>-0.033977</td>\n",
       "      <td>0.079672</td>\n",
       "      <td>-0.780129</td>\n",
       "      <td>-1.017878</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20640 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0      -1.327835  1.052548            0.982143    -0.804819       -0.972476   \n",
       "1      -1.322844  1.043185           -0.607019     2.045890        1.357143   \n",
       "2      -1.332827  1.038503            1.856182    -0.535746       -0.827024   \n",
       "3      -1.337818  1.038503            1.856182    -0.624215       -0.719723   \n",
       "4      -1.337818  1.038503            1.856182    -0.462404       -0.612423   \n",
       "...          ...       ...                 ...          ...             ...   \n",
       "20635  -0.758826  1.801647           -0.289187    -0.444985       -0.388283   \n",
       "20636  -0.818722  1.806329           -0.845393    -0.888704       -0.922403   \n",
       "20637  -0.823713  1.778237           -0.924851    -0.174995       -0.123608   \n",
       "20638  -0.873626  1.778237           -0.845393    -0.355600       -0.304827   \n",
       "20639  -0.833696  1.750146           -1.004309     0.068408        0.188757   \n",
       "\n",
       "       population  households  median_income  median_house_value  \\\n",
       "0       -0.974429   -0.977033       2.344766            2.129631   \n",
       "1        0.861439    1.669961       2.332238            1.314156   \n",
       "2       -0.820777   -0.843637       1.782699            1.258693   \n",
       "3       -0.766028   -0.733781       0.932968            1.165100   \n",
       "4       -0.759847   -0.629157      -0.012881            1.172900   \n",
       "...           ...         ...            ...                 ...   \n",
       "20635   -0.512592   -0.443449      -1.216128           -1.115804   \n",
       "20636   -0.944405   -1.008420      -0.691593           -1.124470   \n",
       "20637   -0.369537   -0.174042      -1.142593           -0.992746   \n",
       "20638   -0.604429   -0.393753      -1.054583           -1.058608   \n",
       "20639   -0.033977    0.079672      -0.780129           -1.017878   \n",
       "\n",
       "       ocean_proximity_<1H OCEAN  ocean_proximity_INLAND  \\\n",
       "0                              0                       0   \n",
       "1                              0                       0   \n",
       "2                              0                       0   \n",
       "3                              0                       0   \n",
       "4                              0                       0   \n",
       "...                          ...                     ...   \n",
       "20635                          0                       1   \n",
       "20636                          0                       1   \n",
       "20637                          0                       1   \n",
       "20638                          0                       1   \n",
       "20639                          0                       1   \n",
       "\n",
       "       ocean_proximity_ISLAND  ocean_proximity_NEAR BAY  \\\n",
       "0                           0                         1   \n",
       "1                           0                         1   \n",
       "2                           0                         1   \n",
       "3                           0                         1   \n",
       "4                           0                         1   \n",
       "...                       ...                       ...   \n",
       "20635                       0                         0   \n",
       "20636                       0                         0   \n",
       "20637                       0                         0   \n",
       "20638                       0                         0   \n",
       "20639                       0                         0   \n",
       "\n",
       "       ocean_proximity_NEAR OCEAN  \n",
       "0                               0  \n",
       "1                               0  \n",
       "2                               0  \n",
       "3                               0  \n",
       "4                               0  \n",
       "...                           ...  \n",
       "20635                           0  \n",
       "20636                           0  \n",
       "20637                           0  \n",
       "20638                           0  \n",
       "20639                           0  \n",
       "\n",
       "[20640 rows x 14 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def encode(df):\n",
    "    cat_values = ['ocean_proximity']\n",
    "    \n",
    "    encoder = OneHotEncoder()\n",
    "    encoder.fit(df[cat_values])\n",
    "    columns = [cat_values[0] + '_' + cat_name for cat_name in encoder.categories_][0]\n",
    "    encoded = pd.DataFrame(encoder.transform(df[cat_values]).toarray(), columns=columns)\n",
    "    return pd.concat([df, encoded.astype(int)], axis=1).drop('ocean_proximity', axis=1)\n",
    "\n",
    "\n",
    "df = encode(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Então, basicamente criei três funções, uma para cada tarefa e vamos modificando o `DataFrame` original até ele se tornar a matriz `X` que vamos passar para nosso modelo de Machine Learning (usando `.fit`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines\n",
    "\n",
    "Agora vejamos como fazer o mesmo processo, mas utilizando Pipelines. \n",
    "\n",
    "Para criar um `Pipeline`, importamos esse objeto e o instanciamos passando uma lista de tuplas. \n",
    "- O primeiro valor da tupla é o nome daquele passo na nossa linha de montagem;\n",
    "- O segundo valor é um `Transformer` do `sklearn`. Ou seja, deve ser um objeto que possua os métodos `transform` e `fit` (pelo menos).\n",
    "\n",
    "Vamos falar mais em detalhes de `Transformers` mais para frente.\n",
    "\n",
    "**_Nota_**: o mais correto é dizer que todos os passos devem ser `Transformers`, exceto o último, que pode ser um `Estimator` (ou seja, possuir o método `predict`).\n",
    "\n",
    "Após criar esse `Pipeline`, podemos chamar os seus métodos `fit` e `transform`. Basicamente, o que ele faz é chamar em sequência cada `Transformer` passando para o próximo a saída retornada pelo anterior. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.32783522,  1.05254828,  0.98214266, ..., -0.97703285,\n",
       "         2.34476576,  2.12963148],\n",
       "       [-1.32284391,  1.04318455, -0.60701891, ...,  1.66996103,\n",
       "         2.33223796,  1.31415614],\n",
       "       [-1.33282653,  1.03850269,  1.85618152, ..., -0.84363692,\n",
       "         1.7826994 ,  1.25869341],\n",
       "       ...,\n",
       "       [-0.8237132 ,  1.77823747, -0.92485123, ..., -0.17404163,\n",
       "        -1.14259331, -0.99274649],\n",
       "       [-0.87362627,  1.77823747, -0.84539315, ..., -0.39375258,\n",
       "        -1.05458292, -1.05860847],\n",
       "       [-0.83369581,  1.75014627, -1.00430931, ...,  0.07967221,\n",
       "        -0.78012947, -1.01787803]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "     ('fillna', SimpleImputer(strategy='median')),\n",
    "     ('scaler', StandardScaler()),\n",
    "])\n",
    "\n",
    "num_values = list(df.columns[:9])\n",
    "num_pipeline.fit(df[num_values])\n",
    "num_df_transformed = num_pipeline.transform(df[num_values])\n",
    "num_df_transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare com o `DataFrame` que geramos pelo pré-processamento anteriormente e você verá que o resultado é o mesmo. A diferença é que aqui temos diretamente um `ndarray` do `numpy` ao invés de um `DataFrame` do `pandas` (na prática, não muda muito, pois o método `fit` de um estimador transforma internamente `DataFrames` em `ndarrays`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformações diferentes para colunas diferentes\n",
    "\n",
    "Bem, agora precisamos fazer o One-Hot Encoding na coluna `ocean_proximity` e juntar com essa matriz que o `Pipeline` gerou, certo?\n",
    "\n",
    "Infelizmente, apenas com `Pipelines` isso não é possível, pois o `Pipeline` não considera as diferentes colunas de uma matriz. Ele apenas aplica as transformações (é por isso que na hora de dar fit e transform, eu chamo `df[num_values]` ao invés de `df` inteiro).\n",
    "\n",
    "Entretanto, o objeto `ColumnTransformer` nos permite fazer exatamente o que precisamos: transformar um conjunto de colunas de um jeito e um outro conjunto de colunas de outro e juntar essas colunas em uma única matriz.\n",
    "\n",
    "Eles funcionam muito similar a `Pipelines`, a diferença é que a tupla recebe um valor a mais: as colunas em que aquela transformação será aplicada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.32783522,  1.05254828,  0.98214266, ...,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       [-1.32284391,  1.04318455, -0.60701891, ...,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       [-1.33282653,  1.03850269,  1.85618152, ...,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       ...,\n",
       "       [-0.8237132 ,  1.77823747, -0.92485123, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.87362627,  1.77823747, -0.84539315, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.83369581,  1.75014627, -1.00430931, ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "cat_values = ['ocean_proximity']\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "    ('numeric', num_pipeline, num_values), \n",
    "    ('categorical', OneHotEncoder(), cat_values)\n",
    "])\n",
    "\n",
    "df = pd.read_csv(input_path)\n",
    "X = full_pipeline.fit_transform(df)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que o objeto `Pipeline` também é um `Transformer` (pois tem os métodos `fit` e `transform`), então podemos considerá-lo como se fosse uma caixa preta e passar para nosso `ColumnTransformer`.\n",
    "\n",
    "E é isso, temos exatamente a mesma coisa que tínhamos feito antes, mas de uma forma muuito mais prática (claro, entender como `Pipelines` funcionam talvez não seja exatamente fácil, mas com certeza recompensa muito).\n",
    "\n",
    "Esse tutorial poderia parar por aqui. Mas vamos ver algumas outras coisinhas que podemos fazer utilizando `Pipelines`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criando seus próprios Transformers\n",
    "\n",
    "O sklearn nos fornece vários transformadores nativos, mas podemos querer criar outros. Um exemplo muito prático é fazer um `Transformer` que gere novas features do seu processo de Feature Engineering. Outro exemplo seria um `Transformer` que matém apenas determinadas features do Data Set (Feature Selection).\n",
    "\n",
    "Vamos mostrar uma mistura desses dois exemplos. Vou criar um `Transformer` que cria duas novas features e tem um parâmetro booleano se devemos criar ou não uma terceira nova feature (assim poderemos testar mais para frente se incluir ou não incluir essa feature é melhor ou não). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para criar um `Transformer`, basicamente basta criar uma classe que implemente os métodos `fit` e `transform`, como já falei (sim, não precisa herdar de nenhuma classe do `sklearn` com o nome `Transformer` ou coisa do tipo. Mostrei isso no Apêndice A do notebook).\n",
    "\n",
    "Entretanto, existem duas classes que costumamos herdar, pois elas nos ajudam:\n",
    "- `TransformerMixin` cria para nós um método `fit_transform` automaticamente usando nossos método `fit` e `transform`; e\n",
    "- `BaseEstimator` cria para nós os métodos `set_params` e `get_params` que são utilizados pelo `GridSearchCV` internamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-122.23, 37.88, 41.0, ..., 6.984126984126984, 2.5555555555555554,\n",
       "        0.14659090909090908],\n",
       "       [-122.22, 37.86, 21.0, ..., 6.238137082601054, 2.109841827768014,\n",
       "        0.15579659106916466],\n",
       "       [-122.24, 37.85, 52.0, ..., 8.288135593220339, 2.8022598870056497,\n",
       "        0.12951601908657123],\n",
       "       ...,\n",
       "       [-121.22, 39.43, 17.0, ..., 5.20554272517321, 2.325635103926097,\n",
       "        0.21517302573203195],\n",
       "       [-121.32, 39.43, 18.0, ..., 5.329512893982808, 2.1232091690544412,\n",
       "        0.21989247311827956],\n",
       "       [-121.24, 39.37, 16.0, ..., 5.254716981132075, 2.616981132075472,\n",
       "        0.22118491921005387]], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class CreateNewFeatures(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, add_bedrooms_per_room=True):\n",
    "        self.rooms_ix = 3\n",
    "        self.bedrooms_ix = 4\n",
    "        self.population_ix = 5\n",
    "        self.households_ix = 6\n",
    "        self.add_bedrooms_per_room = add_bedrooms_per_room\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self # não fazemos nada\n",
    "    \n",
    "    def transform(self, X):\n",
    "        rooms_per_household = X[:, self.rooms_ix] / X[:, self.households_ix]\n",
    "        population_per_household = X[:, self.population_ix] / X[:, self.households_ix]\n",
    "        if self.add_bedrooms_per_room:\n",
    "            bedrooms_per_room = X[:, self.bedrooms_ix] / X[:, self.rooms_ix]\n",
    "            return np.c_[X, rooms_per_household, population_per_household, bedrooms_per_room]\n",
    "        return np.c_[X, rooms_per_household, population_per_household]\n",
    "\n",
    "new_features = CreateNewFeatures(add_bedrooms_per_room=True)\n",
    "housing_extra_features = new_features.transform(df.values)\n",
    "housing_extra_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E pronto, temos um `Transformer` feito por nós mesmos. O limite do que se pode fazer é basicamente definido pela nossa imaginação =)\n",
    "\n",
    "Agora podemos utilizar esses `Transformers` na nossa `Pipeline` de antes para deixá-la mais sofisticada ainda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.32783522,  1.05254828,  0.98214266, ...,  0.62855945,\n",
       "        -0.04959654, -1.02998783],\n",
       "       [-1.32284391,  1.04318455, -0.60701891, ...,  0.32704136,\n",
       "        -0.09251223, -0.8888972 ],\n",
       "       [-1.33282653,  1.03850269,  1.85618152, ...,  1.15562047,\n",
       "        -0.02584253, -1.29168566],\n",
       "       ...,\n",
       "       [-0.8237132 ,  1.77823747, -0.92485123, ..., -0.09031802,\n",
       "        -0.0717345 ,  0.02113407],\n",
       "       [-0.87362627,  1.77823747, -0.84539315, ..., -0.04021111,\n",
       "        -0.09122515,  0.09346655],\n",
       "       [-0.83369581,  1.75014627, -1.00430931, ..., -0.07044252,\n",
       "        -0.04368215,  0.11327519]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_pipeline = Pipeline([\n",
    "     ('fillna', SimpleImputer(strategy='median')),\n",
    "     ('feature_creator', CreateNewFeatures(add_bedrooms_per_room=True)),\n",
    "     ('scaler', StandardScaler()),\n",
    "])\n",
    "\n",
    "\n",
    "df_transformed = num_pipeline.fit_transform(df[num_values])\n",
    "df_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.32783522,  1.05254828,  0.98214266, ...,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       [-1.32284391,  1.04318455, -0.60701891, ...,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       [-1.33282653,  1.03850269,  1.85618152, ...,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       ...,\n",
       "       [-0.8237132 ,  1.77823747, -0.92485123, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.87362627,  1.77823747, -0.84539315, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.83369581,  1.75014627, -1.00430931, ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessing_pipeline = ColumnTransformer([\n",
    "    ('numeric', num_pipeline, num_values),\n",
    "    ('categorical', OneHotEncoder(), cat_values)\n",
    "])\n",
    "\n",
    "df = pd.read_csv(input_path)\n",
    "X = preprocessing_pipeline.fit_transform(df)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E _voilà_, temos novamente uma matriz prontinha para qualquer modelo de Machine Learning utilizar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines e Hyperparameter Tuning\n",
    "\n",
    "Por fim, uma das funcionalidade que eu mais acho incrível dos `Pipelines` é a capacidade usá-los junto do `GridSearchCV` (ou `RandomizedSearchCV`) e podermos passar parâmetros dos transformadores em si para serem testados.\n",
    "\n",
    "Vamos dar uma olhada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'preprocessing__numeric__feature_creator__add_bedrooms_per_room': True,\n",
       " 'preprocessing__numeric__fillna__strategy': 'median',\n",
       " 'ridge__alpha': 10}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Dividindo o DataFrame em matrizes X (de features) e y (o target)\n",
    "# Além disso, definimos quais colunas são numéricas e quais são categóricas (para usar no ColumnTransformer)\n",
    "target = 'median_house_value'\n",
    "X = df.loc[:, df.columns != target]\n",
    "y = df[target]\n",
    "num_values = np.delete(X.columns, np.where(X.columns == 'ocean_proximity'))\n",
    "cat_values = ['ocean_proximity']\n",
    "\n",
    "# Agora definimos nossas Pipelines\n",
    "num_pipeline = Pipeline([\n",
    "     ('fillna', SimpleImputer(strategy='median')),\n",
    "     ('feature_creator', CreateNewFeatures(add_bedrooms_per_room=True)),\n",
    "     ('scaler', StandardScaler()),\n",
    "])\n",
    "preprocessing_pipeline = ColumnTransformer([\n",
    "    ('numeric', num_pipeline, num_values),\n",
    "    ('categorical', OneHotEncoder(categories=[df['ocean_proximity'].unique()]), cat_values)\n",
    "])\n",
    "final_pipe = Pipeline([\n",
    "    ('preprocessing', preprocessing_pipeline),\n",
    "    ('ridge', Ridge())\n",
    "])\n",
    "\n",
    "# Veja que a última Pipeline tem dois passos: o pré-processamento e o estimador (o Ridge, que é um modelo linear)\n",
    "\n",
    "# Agora tem uma parte que pode ser um pouco complexa, mas basta enteder o que está dentro de o que\n",
    "# Na hora de passar os nomes dos parâmetros para o GridSearch, ele utiliza os nomes que passamos nas tuplas \n",
    "# o utiliza dois underlines para se referir a um parâmetro daquele objeto (seria análogo ao ponto que usamos normalmente)\n",
    "params = {\n",
    "    'preprocessing__numeric__feature_creator__add_bedrooms_per_room' : [False, True],\n",
    "    'preprocessing__numeric__fillna__strategy': ['median', 'mean'],\n",
    "    'ridge__alpha' : [0.1, 1, 10],\n",
    "}\n",
    "\n",
    "# De resto, é tudo igual, passamos o estimador (esse Pipeline é um estimador pois o último passo é o Ridge, que é um estimador)\n",
    "# e passamos os parâmetros, além de outros parâmetros que normalmente usamos em um GridSearch\n",
    "gs = GridSearchCV(final_pipe, params, cv=5, n_jobs=-1)\n",
    "gs.fit(X, y)\n",
    "gs.best_params_ # E temos os melhores parâmetros automaticamente =)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na minha opinião, a parte mais difícil de entender é esses nomes enormes de parâmetros e entender as abstrações de um `Pipeline` (pensar que o `Pipeline` herda o tipo do objeto no último passo - um `Estimator` ou `Transformer`). Por isso, vou deixar uma imagem para ficar mais claro.\n",
    "\n",
    "<img src=\"Arvore-de-Pipelines.jpg\" alt=\"drawing\" width=\"500\"/>\n",
    "\n",
    "Além disso, para saber quais são os parâmetros de um `Pipeline`, podemos utilizar o método `get_params`, que nos retorna um dicionário com cada atributo e seu valor padrão. Olhe o Apêndice B para ver o retorno desse método para o nosso `Pipeline` final."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apêndice A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       ...,\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyTransformer():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return np.ones_like(X)\n",
    "        \n",
    "df = pd.read_csv(input_path)\n",
    "\n",
    "my_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer()),\n",
    "    ('test', MyTransformer()), \n",
    "])\n",
    "\n",
    "my_pipeline.fit_transform(df[num_values])\n",
    "# Mesmo não herdando de nada, o sklearn reconhece nossa classe como um Transformer =)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apêndice B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('preprocessing',\n",
       "   ColumnTransformer(transformers=[('numeric',\n",
       "                                    Pipeline(steps=[('fillna',\n",
       "                                                     SimpleImputer(strategy='median')),\n",
       "                                                    ('feature_creator',\n",
       "                                                     CreateNewFeatures()),\n",
       "                                                    ('scaler', StandardScaler())]),\n",
       "                                    Index(['longitude', 'latitude', 'housing_median_age', 'total_rooms',\n",
       "          'total_bedrooms', 'population', 'households', 'median_income'],\n",
       "         dtype='object')),\n",
       "                                   ('categorical',\n",
       "                                    OneHotEncoder(categories=[array(['NEAR BAY', '<1H OCEAN', 'INLAND', 'NEAR OCEAN', 'ISLAND'],\n",
       "         dtype=object)]),\n",
       "                                    ['ocean_proximity'])])),\n",
       "  ('ridge', Ridge())],\n",
       " 'verbose': False,\n",
       " 'preprocessing': ColumnTransformer(transformers=[('numeric',\n",
       "                                  Pipeline(steps=[('fillna',\n",
       "                                                   SimpleImputer(strategy='median')),\n",
       "                                                  ('feature_creator',\n",
       "                                                   CreateNewFeatures()),\n",
       "                                                  ('scaler', StandardScaler())]),\n",
       "                                  Index(['longitude', 'latitude', 'housing_median_age', 'total_rooms',\n",
       "        'total_bedrooms', 'population', 'households', 'median_income'],\n",
       "       dtype='object')),\n",
       "                                 ('categorical',\n",
       "                                  OneHotEncoder(categories=[array(['NEAR BAY', '<1H OCEAN', 'INLAND', 'NEAR OCEAN', 'ISLAND'],\n",
       "       dtype=object)]),\n",
       "                                  ['ocean_proximity'])]),\n",
       " 'ridge': Ridge(),\n",
       " 'preprocessing__n_jobs': None,\n",
       " 'preprocessing__remainder': 'drop',\n",
       " 'preprocessing__sparse_threshold': 0.3,\n",
       " 'preprocessing__transformer_weights': None,\n",
       " 'preprocessing__transformers': [('numeric',\n",
       "   Pipeline(steps=[('fillna', SimpleImputer(strategy='median')),\n",
       "                   ('feature_creator', CreateNewFeatures()),\n",
       "                   ('scaler', StandardScaler())]),\n",
       "   Index(['longitude', 'latitude', 'housing_median_age', 'total_rooms',\n",
       "          'total_bedrooms', 'population', 'households', 'median_income'],\n",
       "         dtype='object')),\n",
       "  ('categorical',\n",
       "   OneHotEncoder(categories=[array(['NEAR BAY', '<1H OCEAN', 'INLAND', 'NEAR OCEAN', 'ISLAND'],\n",
       "         dtype=object)]),\n",
       "   ['ocean_proximity'])],\n",
       " 'preprocessing__verbose': False,\n",
       " 'preprocessing__numeric': Pipeline(steps=[('fillna', SimpleImputer(strategy='median')),\n",
       "                 ('feature_creator', CreateNewFeatures()),\n",
       "                 ('scaler', StandardScaler())]),\n",
       " 'preprocessing__categorical': OneHotEncoder(categories=[array(['NEAR BAY', '<1H OCEAN', 'INLAND', 'NEAR OCEAN', 'ISLAND'],\n",
       "       dtype=object)]),\n",
       " 'preprocessing__numeric__memory': None,\n",
       " 'preprocessing__numeric__steps': [('fillna',\n",
       "   SimpleImputer(strategy='median')),\n",
       "  ('feature_creator', CreateNewFeatures()),\n",
       "  ('scaler', StandardScaler())],\n",
       " 'preprocessing__numeric__verbose': False,\n",
       " 'preprocessing__numeric__fillna': SimpleImputer(strategy='median'),\n",
       " 'preprocessing__numeric__feature_creator': CreateNewFeatures(),\n",
       " 'preprocessing__numeric__scaler': StandardScaler(),\n",
       " 'preprocessing__numeric__fillna__add_indicator': False,\n",
       " 'preprocessing__numeric__fillna__copy': True,\n",
       " 'preprocessing__numeric__fillna__fill_value': None,\n",
       " 'preprocessing__numeric__fillna__missing_values': nan,\n",
       " 'preprocessing__numeric__fillna__strategy': 'median',\n",
       " 'preprocessing__numeric__fillna__verbose': 0,\n",
       " 'preprocessing__numeric__feature_creator__add_bedrooms_per_room': True,\n",
       " 'preprocessing__numeric__scaler__copy': True,\n",
       " 'preprocessing__numeric__scaler__with_mean': True,\n",
       " 'preprocessing__numeric__scaler__with_std': True,\n",
       " 'preprocessing__categorical__categories': [array(['NEAR BAY', '<1H OCEAN', 'INLAND', 'NEAR OCEAN', 'ISLAND'],\n",
       "        dtype=object)],\n",
       " 'preprocessing__categorical__drop': None,\n",
       " 'preprocessing__categorical__dtype': numpy.float64,\n",
       " 'preprocessing__categorical__handle_unknown': 'error',\n",
       " 'preprocessing__categorical__sparse': True,\n",
       " 'ridge__alpha': 1.0,\n",
       " 'ridge__copy_X': True,\n",
       " 'ridge__fit_intercept': True,\n",
       " 'ridge__max_iter': None,\n",
       " 'ridge__normalize': False,\n",
       " 'ridge__random_state': None,\n",
       " 'ridge__solver': 'auto',\n",
       " 'ridge__tol': 0.001}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_pipe.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusão e Aprofundamento\n",
    "\n",
    "Por hoje é tudo =)\n",
    "\n",
    "Espero que você tenha gostado e aproveitado bastante. \n",
    "\n",
    "Concluímos que os `Pipelines` são uma ferramenta incrível que podemos utilizar para agilizar muito nossa vida como cientistas de dados. Além disso, aprendemos um pouco sobre como o `sklearn` opera (os diferentes tipos de objetos dele) e como criar nossos próprios `Transformers`, além de aplicar diferentes transformações a diferentes colunas utilizando `ColumnTransformers`.\n",
    "\n",
    "Para se aprofundar e revisar, recomendo dar uma buscada no livro de onde eu tirei esses exemplos, que já citei, além de dar uma olhada nos seguintes recursos:\n",
    "\n",
    "[Livro - Hands On Machine Learning](https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/)\n",
    "\n",
    "[Guia do usuário - Pipeline and composite estimators](https://scikit-learn.org/stable/modules/compose.html#combining-estimators)\n",
    "\n",
    "[Documentação Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html)\n",
    "\n",
    "[Documentação make_pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_pipeline.html#sklearn.pipeline.make_pipeline)\n",
    "\n",
    "[Documentação ColumnTransformer](https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html#sklearn.compose.ColumnTransformer)\n",
    "\n",
    "[Documentação TransformedTargetRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.compose.TransformedTargetRegressor.html#sklearn.compose.TransformedTargetRegressor)\n",
    "\n",
    "[Tutorial do towards data science](https://towardsdatascience.com/pipelines-custom-transformers-in-scikit-learn-the-step-by-step-guide-with-python-code-4a7d9b068156)\n",
    "\n",
    "\n",
    "\n",
    "**~Lucas Paiolla, 23/04/2021**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
